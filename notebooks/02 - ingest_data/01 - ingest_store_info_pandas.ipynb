{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import chdir, listdir, makedirs\n",
    "from os.path import exists\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up two directories, to project base directory\n",
    "chdir(\"..\\\\..\")\n",
    "\n",
    "# Defines output directory\n",
    "output_dir = \"data\\\\\"\n",
    "\n",
    "# Makes output directory if it doesn't exist\n",
    "if not exists(output_dir):\n",
    "    makedirs(output_dir)\n",
    "\n",
    "# Gets all files in store_info subfolder\n",
    "paths = listdir('data\\\\store_info\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates empty dataframe to hold store page information\n",
    "df_store_info = pd.DataFrame()\n",
    "\n",
    "# Instantiates empty list to hold files that could not be merged successfully\n",
    "failed_merges = []\n",
    "\n",
    "# Loops through all files...\n",
    "for i, path in enumerate(paths):\n",
    "    try:\n",
    "        # Attempting to read files...\n",
    "        df_store_info_current = pd.read_json(f'data\\\\store_info\\\\{path}', orient='index')\n",
    "        \n",
    "        # Appending last read file to dataframe of all files...\n",
    "        df_store_info = pd.concat([df_store_info, df_store_info_current.transpose()])\n",
    "    except:\n",
    "        # Or appending file name to list of failed merges, if unsuccessful.\n",
    "        failed_merges.append(path)\n",
    "\n",
    "# Shows head of dataframe for spot inspection\n",
    "df_store_info.head().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dtype coercion/cleaning\n",
    "\n",
    "# Integer\n",
    "df_store_info['steam_appid'] = df_store_info['steam_appid'].astype(int)\n",
    "df_store_info['required_age'] = df_store_info['required_age'].astype(int)\n",
    "\n",
    "# Boolean\n",
    "df_store_info['is_free'] = df_store_info['is_free'].astype(bool)\n",
    "df_store_info['controller_support'] = df_store_info['controller_support'] == 'full'\n",
    "df_store_info['is_demo'] = df_store_info['fullgame'].isna()\n",
    "\n",
    "# Category (Should be \"game\" for all)\n",
    "df_store_info['type'] = df_store_info['type'].astype('category')\n",
    "\n",
    "# Text - remove html formatting (sometimes preserving line breaks)\n",
    "df_store_info['detailed_description'] = df_store_info['detailed_description'].str.replace('<br>','\\n').str.replace('<((?!>)(?!<).)+>', '', regex=True).str.strip()\n",
    "df_store_info['about_the_game'] = df_store_info['about_the_game'].str.replace('<((?!>)(?!<).)+>', '', regex=True).str.strip()\n",
    "df_store_info['supported_languages'] = df_store_info['supported_languages'].str.replace('<((?!>)(?!<).)+>', '', regex=True).str.strip()\n",
    "df_store_info['drm_notice'] = df_store_info['drm_notice'].str.replace('<br>','\\n').str.replace('<((?!>)(?!<).)+>', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant values from dictionary fields\n",
    "\n",
    "# Simple extraction\n",
    "df_store_info['price'] = df_store_info['price_overview'].apply(pd.Series)['initial'].fillna(0)/100\n",
    "df_store_info['total_achievements'] = df_store_info['achievements'].apply(pd.Series)['total'].fillna(0).astype(int)\n",
    "df_store_info['released'] = df_store_info['release_date'].apply(pd.Series)['coming_soon']\n",
    "df_store_info['release_date'] = pd.to_datetime(df_store_info['release_date'].apply(pd.Series)['date'], format=\"%b %d, %Y\", errors='coerce')\n",
    "df_store_info['recommendations'] = df_store_info['recommendations'].apply(pd.Series)['total'].fillna(0).astype(int)\n",
    "df_store_info['metacritic'] = df_store_info['metacritic'].apply(pd.Series)['score']\n",
    "\n",
    "# Platform requirements - three fields of dicts\n",
    "for platform in ['pc', 'mac', 'linux']:\n",
    "    df_reqs_curr = df_store_info[f'{platform}_requirements'].apply(pd.Series)\n",
    "    \n",
    "    df_store_info[f'{platform}_requirements_minimum'] = df_reqs_curr['minimum'].str.replace('<br>','\\n').str.replace('<((?!>)(?!<).)+>', '', regex=True).str.replace('Minimum:',\"\").str.strip()\n",
    "    df_store_info[f'{platform}_requirements_recommended'] = df_reqs_curr['recommended'].str.replace('<br>','\\n').str.replace('<((?!>)(?!<).)+>', '', regex=True).str.replace('Recommended:',\"\").str.strip()\n",
    "\n",
    "# Platform comaptibility - list of dicts \n",
    "df_compatibility = df_store_info['platforms'].apply(pd.Series)\n",
    "for platform in ['windows','mac','linux']:\n",
    "    df_store_info['compatible_'+platform] = df_compatibility[platform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categories(df_store_info: pd.DataFrame, target_cols: list):\n",
    "    \"\"\"Helper function for generating one-hot encodings for categories stored as a list of dictionaries containing category id and name.\n",
    "\n",
    "    Args:\n",
    "        df_store_info (pd.DataFrame): Store information dataframe\n",
    "        target_cols (list): List of columns to transform. Feature must be a list of dictionaries, where each dictionary corresponds to a subcategory of the category, and contains a key called \"description\" containing the name of that subcategory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Input dataframe with new columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loops through each of the target columns\n",
    "    for target_col in target_cols:\n",
    "        # Extracts lists of subcategory names from target column\n",
    "        # Uses a gross lambda function to handle empty lists (and to avoid writing a helper function for a helper function)\n",
    "        df_store_info[target_col + \"_names\"] = df_store_info[target_col].apply(\n",
    "            lambda categories: (\n",
    "                [category_dict[\"description\"] for category_dict in categories]\n",
    "                if type(categories) == list\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # From series containing per-game lists of subcategories, generates intermediate dataframe \n",
    "        #   where each record is a game and each field holds the name of a subcategory to which the game belongs.\n",
    "        #  Not all fields have values for all games;\n",
    "        #   A game with 3 subcategories will have three populated fields, and the rest will be NA\n",
    "        df_categories_per_game =  df_store_info[target_col +  \"_names\"].apply(pd.Series)\n",
    "\n",
    "        # Instantiates empty set to hold list of all seen categories\n",
    "        categories_with_na = set()\n",
    "        \n",
    "        # Adds categories to set of categories (enforces uniqueness, except for NA)\n",
    "        for col in df_categories_per_game:\n",
    "            for category in df_categories_per_game[col].unique():\n",
    "                categories_with_na.add(category)\n",
    "        \n",
    "        \n",
    "        # Instantiates empty list to hold names of known categories\n",
    "        \n",
    "        # Iterates through set of categories (including NAs), adding each category to list if it's not na\n",
    "        categories = []\n",
    "        for category in categories_with_na:\n",
    "            # Type checking since \"NA\" is not a string\n",
    "            if type(category) == str:\n",
    "                categories.append(category)\n",
    "        \n",
    "        # Sorts categories\n",
    "        categories.sort()\n",
    "        \n",
    "        # For each \n",
    "        for category in categories:\n",
    "            df_store_info[target_col + ': ' + category] = df_categories_per_game.isin([category]).sum(axis=1) == 1\n",
    "    \n",
    "    return df_store_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categories(df_store_info: pd.DataFrame, category_cols: list):\n",
    "    \"\"\"Helper function for generating one-hot encodings for categories stored as a list of dictionaries containing category id and name.\n",
    "\n",
    "    Args:\n",
    "        df_store_info (pd.DataFrame): Store information dataframe\n",
    "        target_cols (list): List of columns to transform. Feature must be a list of dictionaries, where each dictionary corresponds to a subcategory of the category, and contains a key called \"description\" containing the name of that subcategory.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Input dataframe with new columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loops through each of the target columns\n",
    "    for category in category_cols:\n",
    "        # Extracts lists of subcategory names from target column\n",
    "        # Uses a gross lambda function to handle empty lists (and to avoid writing a helper function for a helper function)\n",
    "        df_store_info[category + \"_names\"] = df_store_info[category].apply(\n",
    "            lambda subcategories: (\n",
    "                [subcategory_dict[\"description\"] for subcategory_dict in subcategories]\n",
    "                if type(subcategories) == list\n",
    "                else []\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # From series containing per-game lists of subcategories, generates intermediate dataframe \n",
    "        #   where each record is a game and each field holds the name of a subcategory to which the game belongs.\n",
    "        #  Not all fields have values for all games;\n",
    "        #   A game with 3 subcategories will have three populated fields, and the rest will be NA\n",
    "        df_subcategories_per_game =  df_store_info[category +  \"_names\"].apply(pd.Series)\n",
    "\n",
    "        # Instantiates empty set to hold list of all seen categories\n",
    "        subcategories_with_na = set()\n",
    "        \n",
    "        # Adds categories to set of categories (enforces uniqueness, except for NA)\n",
    "        for col in df_subcategories_per_game:\n",
    "            for subcategory in df_subcategories_per_game[col].unique():\n",
    "                subcategories_with_na.add(subcategory)\n",
    "        \n",
    "        \n",
    "        # Instantiates empty list to hold names of known categories\n",
    "        \n",
    "        # Iterates through set of categories (including NAs), adding each category to list if it's not na\n",
    "        subcategories = []\n",
    "        for subcategory in subcategories_with_na:\n",
    "            # Type checking since \"NA\" is not a string\n",
    "            if type(subcategory) == str:\n",
    "                subcategories.append(subcategory)\n",
    "        \n",
    "        # Sorts categories\n",
    "        subcategories.sort()\n",
    "        \n",
    "        # For each subcategory, checks whether any of each games' subcategories match that subcategory.\n",
    "        for subcategory in subcategories:\n",
    "            df_store_info[category + ': ' + subcategory] = df_subcategories_per_game.isin([subcategory]).sum(axis=1) == 1\n",
    "    \n",
    "    return df_store_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zacha\\AppData\\Local\\Temp\\ipykernel_54680\\729626719.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_store_info_merged_test['is_demo'] = df_store_info_merged_test['fullgame'].isna()\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of categorical fields stored as a list of dictionaries\n",
    "df_store_info = encode_categories(df_store_info, ['categories','genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanted to be conservative with what data are removed; we only drop these columns because doing so was necessary to save the table.\n",
    "cols_to_drop = [\"pc_requirements\",\n",
    "                \"mac_requirements\",\n",
    "                \"linux_requirements\",\n",
    "                \"package_groups\",\n",
    "                \"ratings\"]\n",
    "\n",
    "for col in cols_to_drop:\n",
    "    df_store_info = df_store_info.drop(col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes table to a parquet file\n",
    "df_store_info.to_parquet(output_dir+\"store_info.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam_rec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
