{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from ast import literal_eval\n",
    "from os import chdir, listdir\n",
    "from os.path import exists\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.distributed import LocalCluster\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates dask cluster\n",
    "cluster = LocalCluster()\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move up two directories, to project base directory\n",
    "chdir(\"..\\\\..\")\n",
    "\n",
    "# Gets all files in store_info subfolder\n",
    "folders = listdir(\"data\\\\reviews\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates empty list to hold file paths\n",
    "paths = []\n",
    "\n",
    "# Gets paths to review JSONs. We only need one json from each folder, so we'll use the first.\n",
    "for folder in listdir(\"data\\\\reviews\\\\\"):\n",
    "    current_game_first_json = \"data\\\\reviews\\\\\" + folder + \"\\\\00000000.json\"\n",
    "    if exists(current_game_first_json):\n",
    "        paths.append(current_game_first_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recommendations(row: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Extracts and formats pandas DataFrame of recommendation summary from dask DataFrame.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): Pandas Series corresponding to one json file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Pandas DataFrame containing recommendation summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parses review information as a dictionary (from string)\n",
    "    dict_recommendations = literal_eval(row[\"query_summary\"])\n",
    "\n",
    "    # Parses review information as a pandas DataFrame. Transposes so one record = one game.\n",
    "    df_recommendations = pd.DataFrame.from_dict(\n",
    "        dict_recommendations, orient=\"index\"\n",
    "    ).transpose()\n",
    "\n",
    "    # Adds appid to review DataFrame\n",
    "    df_recommendations[\"steam_appid\"] = row[\"path\"]\n",
    "\n",
    "    # Coerces columns that should be ints to ints\n",
    "    for int_col in [\n",
    "        \"num_reviews\",\n",
    "        \"review_score\",\n",
    "        \"total_positive\",\n",
    "        \"total_negative\",\n",
    "        \"total_reviews\",\n",
    "        \"steam_appid\",\n",
    "    ]:\n",
    "        df_recommendations[int_col] = df_recommendations[int_col].astype(int)\n",
    "\n",
    "    # Sets index to app id column\n",
    "    df_recommendations = df_recommendations.set_index(\"steam_appid\")\n",
    "\n",
    "    return df_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_recommendations(\n",
    "    batch_paths: list, batch_index: int, batch_count: int, meta: pd.DataFrame\n",
    ") -> dd.DataFrame:\n",
    "    \"\"\"Imports recommendation summaries from a batch of review JSONs.\n",
    "\n",
    "    Args:\n",
    "        batch_paths (list): List of paths to review JSONs. Should refer to some subset of all review JSONs.\n",
    "        batch_index (int): Index of current batch (for progress reporting).\n",
    "        batch_count (int): Total number of batches (for progress reporting).\n",
    "        meta (pd.DataFrame): Empty pandas DataFrame dask uses as a template.\n",
    "\n",
    "    Returns:\n",
    "        dd.DataFrame: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Reads review JSONs into a dask DataFrame\n",
    "    ddf_recommendation_jsons = dd.read_json(batch_paths, include_path_column=True)\n",
    "\n",
    "    # Trims values of path column to just name of containing folder.\n",
    "    # (Review download function uses steam app ids as folder names)\n",
    "    ddf_recommendation_jsons[\"path\"] = (\n",
    "        ddf_recommendation_jsons[\"path\"]\n",
    "        .astype(str)\n",
    "        .str[:-14]\n",
    "        .replace(\".+/\", \"\", regex=True)\n",
    "    )\n",
    "\n",
    "    # Extracts recommendation summaries into dask DataFrame of dask DataFrames (using template)\n",
    "    ddf_recommendations_dfs = ddf_recommendation_jsons.apply(\n",
    "        extract_recommendations, axis=1, meta=meta\n",
    "    )\n",
    "\n",
    "    # Extracts dask DataFrames of recommendation summaries from dask DataFrame;\n",
    "    #   Converts to pandas DataFrames; Concatenates into dask DataFrame\n",
    "    ddf_recommendations = dd.concat(ddf_recommendations_dfs.compute().tolist())\n",
    "\n",
    "    # Progress reporting.\n",
    "    clear_output()\n",
    "    print(f\"Batch {batch_index+1}/{batch_count} processed!\")\n",
    "    \n",
    "    return ddf_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates some variables for batch processing step\n",
    "\n",
    "# Imports template DataFrame so dask knows to to interpret things\n",
    "meta = pd.read_parquet(\"dask_templates\\\\recommendations_meta.parquet\")\n",
    "\n",
    "# Sets batch size. 2^13 works pretty well with 64 GB of RAM;\n",
    "#   You'll probably want to experiment if you have less.\n",
    "#   I'd (naively) recommend 2^12 for 32 GB RAM, 2^11 for 16 GB RAM, etc.\n",
    "batch_size = 2**13\n",
    "\n",
    "# Calculates batch count for better progress reporting.\n",
    "batch_count = len(paths) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing step\n",
    "\n",
    "# Gets list of dask DataFrames of recommendation summaries\n",
    "#   (I'm using a list comprehension to avoid having to name a bunch of DataFrames)\n",
    "list_recommendation_ddfs = [\n",
    "    ingest_recommendations(paths_subset.tolist(), batch_index, batch_count, meta)\n",
    "    for batch_index, paths_subset in enumerate(\n",
    "        np.array_split(paths, len(paths) / batch_size)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates dask DataFrames of recommendation summaries into one dask DataFrame\n",
    "ddf_recommendations = dd.concat(list_recommendation_ddfs)\n",
    "\n",
    "# Cleaning-fills nulls with zero.\n",
    "ddf_recommendations = ddf_recommendations.fillna(0)\n",
    "\n",
    "# Progress print\n",
    "clear_output()\n",
    "print(f\"Recommendation ingest finished!\\nWriting data to parquet...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts dask DataFrame to pandas DataFrame so that parquet is written as file (not folder)\n",
    "df_recommendations = ddf_recommendations.compute()\n",
    "\n",
    "# Writes parquet file\n",
    "df_recommendations.to_parquet(\"data\\\\recommendations.parquet\")\n",
    "\n",
    "# Progress update\n",
    "clear_output()\n",
    "print(f\"Parquet writing finished!\")\n",
    "\n",
    "# Terminates dask client\n",
    "client.shutdown()\n",
    "print(\"Cluster shutdown.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "steam_rec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
